{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5faa4c4",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Machine Learning Exercise 2 - Multiple Linear Regression</h1>\n",
    "<h2 style=\"text-align: center;\">Ajay Badrinath</h2>\n",
    "<h3 style=\"text-align: center;\">21011102020</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a3d35",
   "metadata": {},
   "source": [
    "### House Price Prediction Using Multiple Regression \n",
    "I have Split PreProcess And Helper Functions as Separate Classes for Ease of Use And Code Reusablity\n",
    "\n",
    "\n",
    "Plan: Reduce Number Of Features and Predict using the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56557d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer as s\n",
    "from sklearn.impute import KNNImputer as knn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "data = pd.read_csv(r'D:/house_pred.csv')\n",
    "data_pred=pd.read_csv(r'D:/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6178e32",
   "metadata": {},
   "source": [
    "### PreProcess Class \n",
    "\n",
    "For Performing PreProcessing tasks :\n",
    "    <ul>\n",
    "    <li>Clear Null </li>\n",
    "    <li>Data Imputation -KNN </li>\n",
    "    <li>Drop NA - As There are Null Values in dataset for dtype=object <code>get_all_null()</code></li>\n",
    "    <li>Perform One Hot Encoding on Object Datatypes. Comes to About 271 Columns overall</li>\n",
    "    <li>Perform Standard Scaling to center Data Around Mean - Except to Y(SalePrice)</li>\n",
    "    <li>Remove Correlation Within Range -0.1 to 0.1 w.r.t.to Dependant Sale Price </li>\n",
    "    <li>Compute And Drop Highest vif -Very Expensive operation  WILL HOG YOUR RAM.</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0206adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcess():\n",
    "    #Auto Run Upon Initiation .\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.run()\n",
    "    # PreProcessing  Schedules\n",
    "    def run(self):\n",
    "        self.ClearNull(threshold=0.5)\n",
    "        l=self.get_all_Null(dtype='float64')\n",
    "        self.knn_impute(2,l)\n",
    "        #self.outlier_remove()\n",
    "        self.data=self.data.dropna()\n",
    "        self.one_hot_encoding()\n",
    "        self.StdScale()\n",
    "        self.outlier_remove('SalePrice')\n",
    "        self.drop_correlation()\n",
    "\n",
    "        self.drop_vif(thresh=4.5)\n",
    "\n",
    "    # Remove Correlation \n",
    "    def drop_correlation(self):\n",
    "        k=Utils_Suite(self.data).compute_correlation(0.3)\n",
    "        f=pd.DataFrame(k)\n",
    "        m=list(f[(f['SalePrice']<0.1) & (f['SalePrice']>-0.1)].index)\n",
    "        self.data=self.data.drop(columns=m)\n",
    "\n",
    "    def ClearNull(self,threshold):\n",
    "        x=self.data.isna().sum()>0\n",
    "\n",
    "        for i in  list(x.index):\n",
    "            thresh=self.data[i].isna().sum()/len(self.data)\n",
    "            if(x[i]==True and thresh>threshold):\n",
    "                print(i,self.data[i].isna().sum())\n",
    "                self.data=self.data.drop(i,axis=1)\n",
    "\n",
    "\n",
    "    def knn_impute(self,n_neighbors,col_list):\n",
    "        imputer=knn(n_neighbors=n_neighbors)\n",
    "        for i in col_list:\n",
    "            self.data[i]=imputer.fit_transform(self.data[[i]])[0][0]\n",
    "\n",
    "    def arbitrary_remove(self):\n",
    "        #data=data.drop(columns=['LotFrontage','MasVnrArea','GarageYrBlt'])\n",
    "        self.data=self.data.drop('Id',axis=1)\n",
    "\n",
    "    def get_all_Null(self,dtype=\"\"):\n",
    "        x=self.data.isna().sum()>0\n",
    "        l=[]\n",
    "        for i in  list(x.index):\n",
    "            thresh=self.data[i].isna().sum()/len(self.data)\n",
    "            if(x[i]==True and (data[i].dtypes==dtype) ):\n",
    "                print(i,data[i].isna().sum())\n",
    "                l+=[i]\n",
    "        return l\n",
    "    # Drop Outlier Rows \n",
    "    def outlier_remove(self,col):\n",
    "        \n",
    "        q1=self.data[col].quantile(0.25)\n",
    "        q3=self.data[col].quantile(0.75)\n",
    "        iqr=q3-q1\n",
    "        l_whis=q1-1.5*iqr\n",
    "        u_whis=q3+1.5*iqr\n",
    "        self.data= self.data[(self.data[col]>=l_whis)& (self.data[col]<=u_whis)]\n",
    "        \n",
    "    #Depricated  ....(DONT USE IT - Diminishes the data set )\n",
    "    def outlier_remove_deprecated(self):\n",
    "        for col in self.data.columns:\n",
    "            if self.data[col].dtypes!='object':\n",
    "                \n",
    "                q1=self.data[col].quantile(0.25)\n",
    "                q3=self.data[col].quantile(0.75)\n",
    "                iqr=q3-q1\n",
    "                l_whis=q1-1.5*iqr\n",
    "                u_whis=q3+1.5*iqr\n",
    "                self.data= self.data[(self.data[col]>=l_whis)& (self.data[col]<=u_whis)]\n",
    "        return self.data\n",
    "    # One hot Encoding using get_dummies\n",
    "    def one_hot_encoding(self):\n",
    "        z=(self.data.dtypes=='object')\n",
    "        k=pd.DataFrame(z)\n",
    "        obj_list=list(k[k[0]==True].index)\n",
    "        print(obj_list)\n",
    "        for i in obj_list:\n",
    "            dummy=pd.get_dummies(self.data[i],prefix=i,drop_first=True)\n",
    "            #print(dummy)\n",
    "            self.data=self.data.drop(i,axis=1)\n",
    "            self.data=self.data.join(dummy)\n",
    "            #self.data=pd.concat([self.data,dummy],axis=1)\n",
    "    # standardize data\n",
    "\n",
    "    def StdScale(self):\n",
    "        for i in self.data.columns:\n",
    "            if self.data[i].dtypes!='object' and i!='SalePrice':\n",
    "                scale = StandardScaler().fit(self.data[[i]])\n",
    "    \n",
    "                self.data[i] = scale.transform(self.data[[i]])\n",
    "\n",
    "        \n",
    "    ## DANGER ZONE Col Spare NEEDED To Keep y_pred. RAM HOGGING FUNCTION .\n",
    "    #Use Wisely! Plus Parallize the operation for better efficacy? Maybe???\n",
    "                \n",
    "    def drop_vif(self,thresh=5,col_Spare=['SalePrice','intercept']):\n",
    "\n",
    "        \n",
    "        vif=Utils_Suite(self.data).compute_vif()\n",
    "        z1=vif[vif[\"vif\"]>thresh]\n",
    "        z1=z1.sort_values(by='vif', kind='mergesort',ascending=[False])\n",
    "        while True:\n",
    "            try:\n",
    "                col=z1.iloc[0,0]\n",
    "                if z1.empty:\n",
    "                    break\n",
    "                if col in col_Spare:\n",
    "                    z1=z1.iloc[1:]\n",
    "                    continue\n",
    "                self.data=self.data.drop(col,axis=1)\n",
    "                vif=Utils_Suite(self.data).compute_vif()\n",
    "                z1=vif[vif[\"vif\"]>thresh]\n",
    "                z1=z1.sort_values(by='vif', kind='mergesort',ascending=[False])\n",
    "            except IndexError:\n",
    "                break\n",
    "        \n",
    "    # Wrapper Function to dump data to a variable  \n",
    "    def write_df(self):\n",
    "        return self.data\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb48aefa",
   "metadata": {},
   "source": [
    "### Utility Class \n",
    "This Class Comprises of Helper Functions that Computes:\n",
    "<ul>\n",
    "<li>Correlation wrt Dependant Var-SalePrice</li>\n",
    "<li>Variance Inflation Factor - Highest to Lowest</li>\n",
    "<li>Mutual Information wrt to target variable </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "07f8ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils_Suite():\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def compute_correlation(self,threshold=0.3):\n",
    "        matrix=self.data.corr(numeric_only=True)\n",
    "        x=matrix[(matrix[\"SalePrice\"]<threshold)&(matrix[\"SalePrice\"]>-threshold)][\"SalePrice\"]\n",
    "        return x\n",
    "    def compute_mutual_information(self,thresh=0.1):\n",
    "        enc = OrdinalEncoder()\n",
    "        df_encoded = enc.fit_transform(self.data)\n",
    "        mi_scores = mutual_info_regression(df_encoded, self.data['SalePrice'])\n",
    "        mi_scores_df = pd.DataFrame(mi_scores, index=self.data.columns, columns=['Score'])\n",
    "        return mi_scores_df[mi_scores_df['Score']<thresh]\n",
    "    def compute_vif(self):\n",
    "        x=self.data.iloc[:,:-1]\n",
    "        y=self.data.iloc[:,-1]\n",
    "        x=pd.DataFrame(x)\n",
    "\n",
    "        x['intercept']=1\n",
    "        vif=pd.DataFrame()\n",
    "        vif['variable']=x.columns\n",
    "        vif['vif']=[variance_inflation_factor(x.values,i)for i in range(x.shape[1])]\n",
    "        return vif\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f0112",
   "metadata": {},
   "source": [
    "## Model\n",
    "I Just wanted to Encapsulate The sklearn -out of the box Linear regression class with \n",
    "another one of Mine for Convenience sake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "088ead1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self,x_train,y_train,x_test,y_test):\n",
    "        self.x_train=x_train\n",
    "        self.x_test=x_test   \n",
    "        self.y_train=y_train\n",
    "        self.y_test=y_test\n",
    "        self.y_pred=0\n",
    "\n",
    "    def fit(self):\n",
    "            self.reg = LinearRegression()\n",
    "            self.reg.fit(self.x_train,self.y_train)\n",
    "            return self.reg\n",
    "    def predict(self):\n",
    "         self.y_pred=self.reg.predict(self.x_test)\n",
    "         return self.y_pred\n",
    "    def score_metric(self):\n",
    "         return r2_score(self.y_test,self.y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "ad7a20e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alley 1369\n",
      "PoolQC 1453\n",
      "Fence 1179\n",
      "MiscFeature 1406\n",
      "LotFrontage 259\n",
      "MasVnrArea 8\n",
      "GarageYrBlt 81\n",
      "['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'SaleType', 'SaleCondition']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    }
   ],
   "source": [
    "k=PreProcess(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "8a5e4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=k.write_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "a6f2e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "col=list(data.columns)\n",
    "col.remove('SalePrice')\n",
    "col.append('SalePrice')\n",
    "data=data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "8ae06ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.iloc[:,:-1]\n",
    "y=data.iloc[:,-1]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ab5bda",
   "metadata": {},
   "source": [
    "#### Just Cross verifying VIF as deciding on sweet spot (3-5) has a lot of impact on the model accuracy (About 10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "50951ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1752: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    }
   ],
   "source": [
    "u=Utils_Suite(data).compute_vif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "f7a9bd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>vif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BsmtFinSF1</td>\n",
       "      <td>4.060141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>SaleType_WD</td>\n",
       "      <td>4.073770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>SaleCondition_Partial</td>\n",
       "      <td>4.841633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 variable       vif\n",
       "6              BsmtFinSF1  4.060141\n",
       "78            SaleType_WD  4.073770\n",
       "80  SaleCondition_Partial  4.841633"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u[u['vif']>4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac621c0",
   "metadata": {},
   "source": [
    "#### Fitting the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "bd2fc82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_Model=Model(x_train,y_train,x_test,y_test)\n",
    "reg=MR_Model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f87b29",
   "metadata": {},
   "source": [
    "#### Model Performance Metric (At the Max All I could get was around 80% with this training data...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "6151f07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7909355723036731"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "e9feff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=MR_Model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab48764",
   "metadata": {},
   "source": [
    "#### Score As Per R<sup>2</sup> Metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "5cf5f440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.689393821581118"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MR_Model.score_metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ee489",
   "metadata": {},
   "source": [
    "#### RMSE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "0081f8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36857.56429672354"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f90665e",
   "metadata": {},
   "source": [
    "#### My Comments (Inferences)\n",
    "\n",
    "\n",
    "As the Number of Features Increases The prediction is poor (39%) On the Other Hand when the Features are very Less As Say Executing <code>drop_vif</code> for  vif>3 \n",
    "\n",
    "(Around 150 Columns will be Truncated ) Here Also the Model does not have a good fit even for training data .\n",
    "\n",
    "The Challenge is to Find the Sweet Spot of Settling between 50 Impactful Columns for a decent fit (79%) what I obtained here.\n",
    "\n",
    "So I had used Some Statistical Measures in the PreProcessing Steps to compute the same and drop necessary columns that do not contribute in any way(+/-)MultiColinearity Tests....\n",
    "\n",
    "\n",
    " In order to automate the process I wrote Down Preprocessing as a Generic Class .. So It Happens that Computing VIF Is a resource Intensive Task\n",
    "\n",
    " \n",
    "  (Atleast For My Above Code Complexity O<sup>n<sup>2</sup>log(n)</sup> )\n",
    " \n",
    "Takes About Roughly (1m 50 s ) to finish preprocessing ...  \n",
    " \n",
    " \n",
    " Concatenation of test data with train data (1700 rows+) leads to Mem Overflow.... \n",
    "\n",
    "\n",
    "Ofcourse the Performance can be bumped up without sorting by finding Max within dataframe .... \n",
    "\n",
    "Multi Regression :\n",
    "\n",
    "                \n",
    "                RMSE:36857\n",
    "                R_2 Metric:0.68\n",
    "                coefficient of determination :79\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
